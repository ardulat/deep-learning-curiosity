\relax 
\citation{Mikolov2010NeuralLM}
\citation{unsupervised}
\citation{unsupervised}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2011ExtensionsOR}
\citation{Zaremba2014LSTM}
\citation{Salakhutdinov2017Softmax}
\citation{Mikolov2011SubwordLM}
\citation{Quoc2017Reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Next word prediction in a text.}}{1}}
\newlabel{fig:sequence}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Recurrent Neural Networks based Language Models}{1}}
\citation{deeplearning}
\citation{Mikolov2010NeuralLM,Mikolov2011ExtensionsOR,Zaremba2014LSTM}
\citation{Mikolov2010NeuralLM}
\citation{rnn}
\citation{rnn}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2011ExtensionsOR}
\citation{Mikolov2011ExtensionsOR}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Recurrent Neural Network}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Language Models}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Simple recurrent neural network from \cite  {Mikolov2010NeuralLM}}}{2}}
\newlabel{fig:rnn}{{2}{2}}
\citation{Zaremba2014LSTM}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Quoc2017Reinforcement}
\citation{Mikolov2011SubwordLM}
\citation{Quoc2017Reinforcement}
\citation{Mikolov2011SubwordLM}
\citation{Mikolov2011SubwordLM}
\citation{Mikolov2011SubwordLM}
\@writefile{toc}{\contentsline {section}{\numberline {III}Other Language Models}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Subword-level Language Modeling}{3}}
\newlabel{fig:subword}{{\unhbox \voidb@x \hbox {III-A}}{3}}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Single model perplexity on validation and test sets on Penn Treebank \cite  {Salakhutdinov2017Softmax}.}}{4}}
\newlabel{tab:softmax}{{I}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Single model perplexity on the test set of the Penn Treebank language modeling task \cite  {Quoc2017Reinforcement}.}}{4}}
\newlabel{tab:search}{{II}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Reinforcement Learning}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An overview of Neural Architecture Search from \cite  {Quoc2017Reinforcement}}}{4}}
\newlabel{fig:rl}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The computation graph of the recurrent cell constructed from example predictions of the controller in \cite  {Quoc2017Reinforcement}}}{4}}
\newlabel{fig:seach}{{4}{4}}
\citation{Quoc2017Reinforcement}
\bibstyle{IEEEtran}
\bibdata{reference}
\bibcite{Mikolov2010NeuralLM}{1}
\bibcite{unsupervised}{2}
\bibcite{Mikolov2011ExtensionsOR}{3}
\bibcite{Zaremba2014LSTM}{4}
\bibcite{Salakhutdinov2017Softmax}{5}
\bibcite{Mikolov2011SubwordLM}{6}
\bibcite{Quoc2017Reinforcement}{7}
\bibcite{deeplearning}{8}
\bibcite{rnn}{9}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion and future work}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}

\relax 
\citation{Mikolov2010NeuralLM}
\citation{unsupervised}
\citation{unsupervised}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2011ExtensionsOR}
\citation{Zaremba2014LSTM}
\citation{Salakhutdinov2017Softmax}
\citation{Mikolov2011SubwordLM}
\citation{Quoc2017Reinforcement}
\citation{deeplearning}
\citation{Mikolov2010NeuralLM}
\citation{rnn}
\citation{rnn}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Next word prediction in a text.}}{1}}
\newlabel{fig:sequence}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Recurrent Neural Networks based Language Models}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Recurrent Neural Network}{1}}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2010NeuralLM}
\citation{Mikolov2011ExtensionsOR}
\citation{Mikolov2011ExtensionsOR}
\citation{Zaremba2014LSTM}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Salakhutdinov2017Softmax}
\citation{Quoc2017Reinforcement}
\citation{Mikolov2011SubwordLM}
\citation{Mikolov2011SubwordLM}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Language Models}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Simple recurrent neural network from \cite  {Mikolov2010NeuralLM}}}{2}}
\newlabel{fig:rnn}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Other Language Models}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Subword-level Language Modeling}{2}}
\newlabel{fig:subword}{{\unhbox \voidb@x \hbox {III-A}}{2}}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\citation{Quoc2017Reinforcement}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Single model perplexity on validation and test sets on Penn Treebank \cite  {Salakhutdinov2017Softmax}.}}{3}}
\newlabel{tab:softmax}{{I}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Single model perplexity on the test set of the Penn Treebank language modeling task \cite  {Quoc2017Reinforcement}.}}{3}}
\newlabel{tab:search}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Reinforcement Learning}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An overview of Neural Architecture Search from \cite  {Quoc2017Reinforcement}}}{3}}
\newlabel{fig:rl}{{3}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{3}}
\bibstyle{IEEEtran}
\bibdata{reference}
\bibcite{Mikolov2010NeuralLM}{1}
\bibcite{unsupervised}{2}
\bibcite{Mikolov2011ExtensionsOR}{3}
\bibcite{Zaremba2014LSTM}{4}
\bibcite{Salakhutdinov2017Softmax}{5}
\bibcite{Mikolov2011SubwordLM}{6}
\bibcite{Quoc2017Reinforcement}{7}
\bibcite{deeplearning}{8}
\bibcite{rnn}{9}
\@writefile{toc}{\contentsline {section}{References}{4}}
